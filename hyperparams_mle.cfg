[ALL_PARAMS]
cross-entropy-label-smoothing-factor=0.1
max-lm-seq-len=65536
lm-aux-seq-len=128
grad-acc-every=16
mask-proba=0.2
optim-name="adam"
warmup-steps=8000
noam-factor-fine-tune=0.01
model-name="facebook/bart-large"
max-pos-embeddings=1568
ds-config-file-path="./ds_config_mle.json"
base-data-dir="multi_task_data"
batch-size=4
num-epoch=7
learning-rate=2e-5
save-dir="./saved_model_mle"
mle-qfs=True
start-epoch=6
prof-force-proba-max=0.5
clm-weight=0.05
mlm-weight=0.05
qfs-mle-weight=0.6
qfs-rl-weight=0.4
do-clm=0
do-mlm=0
do-qfs-mle=1
do-qfs-rl=1
saved-data=False