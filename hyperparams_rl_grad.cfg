[ALL_PARAMS]
cross-entropy-label-smoothing-factor=0.1
max-lm-seq-len=65536
lm-aux-seq-len=128
grad-acc-every=64
mask-proba=0.2
optim-name="adam"
warmup-steps=8000
noam-factor-fine-tune=0.01
model-name="facebook/bart-large"
max-pos-embeddings=1568
ds-config-file-path="./ds_config_rl.json"
base-data-dir="multi_task_data"
batch-size=2
num-epoch=5
learning-rate=5e-7
save-dir="./saved_model_rl_scheduled_sample_grad_sbert"
mle-qfs=False
start-epoch=1
rl-window=15
sampling-type="scheduled-sample" # "rl-window" or "scheduled-sample"
last-pass-grad-only=False
num-dec-pass=2
scheduled-sampling-temp=0.5
use-sim-score=False
use-sbert-score=True
use-bleu-score=False
use-fscore=False
len-penalize=False
max-ngram=3
context-window=30
prof-force-proba-max=0.1
clm-weight=0.05
mlm-weight=0.05
qfs-mle-weight=0.1
qfs-rl-weight=0.9
do-clm=0
do-mlm=0
do-qfs-mle=1
do-qfs-rl=1
saved-data=False
use-pe-score=False
pe-model-name="bert-large-cased"
pe-model-ckpt="pe_embed/large_model.pt"